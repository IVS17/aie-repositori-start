{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56457646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Импорт библиотек\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Настройки отображения\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Scikit-learn импорты\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Загрузка данных\n",
    "\n",
    "# %%\n",
    "# Определяем путь к данным\n",
    "data_path = Path(\"../../seminars/S05/S05-hw-dataset.csv\")\n",
    "\n",
    "# Если файл не найден, попробуем другой путь\n",
    "if not data_path.exists():\n",
    "    # Пробуем найти файл в текущей директории\n",
    "    data_path = Path(\"S05-hw-dataset.csv\")\n",
    "    if not data_path.exists():\n",
    "        # Если всё ещё не найден, попробуем загрузить из GitHub\n",
    "        print(\"Файл не найден локально. Пожалуйста, убедитесь, что файл находится в правильной директории.\")\n",
    "        # Для примера создадим синтетические данные\n",
    "        print(\"Создаю синтетические данные для демонстрации...\")\n",
    "        np.random.seed(42)\n",
    "        n_samples = 3000\n",
    "        data = {\n",
    "            'client_id': np.arange(n_samples),\n",
    "            'age': np.random.randint(21, 70, n_samples),\n",
    "            'income': np.random.randint(15000, 200000, n_samples),\n",
    "            'years_employed': np.random.randint(0, 40, n_samples),\n",
    "            'credit_score': np.random.randint(300, 850, n_samples),\n",
    "            'debt_to_income': np.random.uniform(0, 1, n_samples),\n",
    "            'num_credit_cards': np.random.randint(0, 8, n_samples),\n",
    "            'num_late_payments': np.random.poisson(1.5, n_samples),\n",
    "            'has_mortgage': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\n",
    "            'has_car_loan': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\n",
    "            'savings_balance': np.random.randint(0, 50000, n_samples),\n",
    "            'checking_balance': np.random.randint(-5000, 20000, n_samples),\n",
    "            'region_risk_score': np.random.uniform(0, 1, n_samples),\n",
    "            'phone_calls_to_support_last_3m': np.random.poisson(2, n_samples),\n",
    "            'active_loans': np.random.randint(0, 5, n_samples),\n",
    "            'customer_tenure_years': np.random.randint(0, 20, n_samples),\n",
    "            'default': np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = pd.read_csv(data_path)\n",
    "else:\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Первичный анализ данных\n",
    "\n",
    "# %%\n",
    "# Первые строки данных\n",
    "print(\"Первые 5 строк датасета:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Информация о столбцах и типах данных\n",
    "print(\"Информация о датасете:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Базовые статистики для числовых признаков\n",
    "print(\"Описательные статистики:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Распределение целевой переменной\n",
    "print(\"Распределение целевой переменной (default):\")\n",
    "print(df['default'].value_counts(normalize=True))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Размер датасета\n",
    "print(f\"Размер датасета: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Наблюдения после первичного анализа:\n",
    "# \n",
    "# 1. **Размер данных**: В датасете 3000 строк и 17 столбцов.\n",
    "# 2. **Целевая переменная**: Распределение классов составляет примерно 60% (нет дефолта) и 40% (дефолт). Задача не идеально сбалансирована, но и не экстремально перекошена.\n",
    "# 3. **Типы данных**: Все признаки числовые (целые или вещественные числа).\n",
    "# 4. **Пропуски**: Нет пропущенных значений (все столбцы содержат 3000 ненулевых значений).\n",
    "# 5. **Аномалии**: На первый взгляд явных аномалий нет. Все числовые признаки находятся в разумных диапазонах.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Визуальный анализ\n",
    "\n",
    "# %%\n",
    "# Создаем директорию для сохранения графиков\n",
    "figures_dir = Path(\"figures\")\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Распределение целевой переменной\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['default'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Распределение целевой переменной (default)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Дефолт (0 - нет, 1 - да)', fontsize=12)\n",
    "plt.ylabel('Количество наблюдений', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(figures_dir / 'target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Распределение некоторых числовых признаков\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Распределение числовых признаков', fontsize=16, fontweight='bold')\n",
    "\n",
    "features_to_plot = ['age', 'income', 'credit_score', 'debt_to_income', 'savings_balance', 'checking_balance']\n",
    "colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'plum', 'lightblue']\n",
    "\n",
    "for idx, (feature, color) in enumerate(zip(features_to_plot, colors)):\n",
    "    ax = axes[idx//3, idx%3]\n",
    "    df[feature].hist(bins=30, ax=ax, color=color, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(feature, fontsize=10)\n",
    "    ax.set_ylabel('Частота', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'numerical_features_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Матрица корреляций (только для нескольких ключевых признаков)\n",
    "key_features = ['age', 'income', 'credit_score', 'debt_to_income', 'num_late_payments', 'default']\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[key_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Матрица корреляций (ключевые признаки)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Подготовка признаков и таргета\n",
    "\n",
    "# %%\n",
    "# Создаем копию датасета для работы\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Удаляем client_id, так как это просто идентификатор\n",
    "if 'client_id' in df_clean.columns:\n",
    "    df_clean = df_clean.drop('client_id', axis=1)\n",
    "\n",
    "# Проверяем диапазоны ключевых признаков\n",
    "print(\"Проверка диапазонов признаков:\")\n",
    "print(f\"debt_to_income: [{df_clean['debt_to_income'].min():.2f}, {df_clean['debt_to_income'].max():.2f}]\")\n",
    "print(f\"region_risk_score: [{df_clean['region_risk_score'].min():.2f}, {df_clean['region_risk_score'].max():.2f}]\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Выделяем матрицу признаков и вектор таргета\n",
    "X = df_clean.drop('default', axis=1)  # Все признаки кроме таргета\n",
    "y = df_clean['default']  # Целевая переменная\n",
    "\n",
    "print(f\"Размер матрицы признаков X: {X.shape}\")\n",
    "print(f\"Размер вектора таргета y: {y.shape}\")\n",
    "print(f\"Признаки: {list(X.columns)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Разделение данных на train/test\n",
    "\n",
    "# %%\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  # 20% данных в тестовую выборку\n",
    "    random_state=42,  # Для воспроизводимости\n",
    "    stratify=y  # Сохраняем баланс классов\n",
    ")\n",
    "\n",
    "print(\"Размеры выборок после разделения:\")\n",
    "print(f\"Обучающая выборка: X_train = {X_train.shape}, y_train = {y_train.shape}\")\n",
    "print(f\"Тестовая выборка: X_test = {X_test.shape}, y_test = {y_test.shape}\")\n",
    "\n",
    "print(\"\\nРаспределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nРаспределение классов в тестовой выборке:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Бейзлайн-модель (DummyClassifier)\n",
    "\n",
    "# %%\n",
    "# Создаем и обучаем бейзлайн-модель\n",
    "print(\"=\"*80)\n",
    "print(\"БЕЙЗЛАЙН-МОДЕЛЬ (DummyClassifier)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Создаем бейзлайн модель, которая предсказывает наиболее частый класс\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred_dummy = dummy_model.predict(X_test)\n",
    "\n",
    "# Метрики качества для бейзлайна\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "# Для ROC-AUC нужны вероятности, но DummyClassifier с strategy=\"most_frequent\"\n",
    "# всегда предсказывает один класс, поэтому ROC-AUC не определен\n",
    "# Вместо этого используем стратегию \"stratified\"\n",
    "dummy_model_stratified = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_model_stratified.fit(X_train, y_train)\n",
    "y_proba_dummy = dummy_model_stratified.predict_proba(X_test)[:, 1]\n",
    "roc_auc_dummy = roc_auc_score(y_test, y_proba_dummy)\n",
    "\n",
    "print(f\"\\nМетрики бейзлайн-модели (most_frequent):\")\n",
    "print(f\"Accuracy: {accuracy_dummy:.4f}\")\n",
    "print(f\"\\nМетрики бейзлайн-модели (stratified):\")\n",
    "print(f\"ROC-AUC: {roc_auc_dummy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Комментарий:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Бейзлайн-модель, предсказывающая наиболее частый класс (нет дефолта), \n",
    "даёт accuracy примерно 0.6, что соответствует доле отрицательного класса в данных.\n",
    "\n",
    "ROC-AUC для стратегии 'stratified' составляет около 0.5, что ожидаемо для случайного классификатора.\n",
    "\n",
    "Важно иметь эту точку отсчёта, чтобы понимать, насколько наша модель лучше случайного угадывания.\n",
    "\"\"\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Логистическая регрессия с подбором гиперпараметров\n",
    "\n",
    "# %%\n",
    "print(\"=\"*80)\n",
    "print(\"ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Создаем pipeline: стандартизация + логистическая регрессия\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),  # Стандартизация признаков\n",
    "    (\"logreg\", LogisticRegression(\n",
    "        max_iter=1000,  # Увеличиваем число итераций для сходимости\n",
    "        random_state=42,\n",
    "        solver='lbfgs'  # Хороший солвер по умолчанию\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Определяем сетку гиперпараметров для перебора\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  # Параметр регуляризации\n",
    "    'logreg__penalty': ['l2'],  # L2 регуляризация\n",
    "    # Можно добавить другие параметры, например:\n",
    "    # 'logreg__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Настраиваем GridSearchCV для поиска лучших гиперпараметров\n",
    "grid_search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-кратная кросс-валидация\n",
    "    scoring='roc_auc',  # Оптимизируем по ROC-AUC\n",
    "    n_jobs=-1,  # Используем все ядра процессора\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Обучаем модель с перебором гиперпараметров\n",
    "print(\"\\nНачинаем подбор гиперпараметров...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"\\nЛучшие параметры найденные GridSearchCV:\")\n",
    "best_params = grid_search.best_params_\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nЛучший ROC-AUC на кросс-валидации: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Используем лучшую модель\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Оценка лучшей модели на тестовой выборке\n",
    "\n",
    "# %%\n",
    "# Предсказания лучшей модели\n",
    "y_pred_logreg = best_model.predict(X_test)\n",
    "y_proba_logreg = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Вычисляем метрики\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_proba_logreg)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "\n",
    "print(\"\\nМетрики лучшей модели на тестовой выборке:\")\n",
    "print(f\"Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_logreg:.4f}\")\n",
    "print(f\"Precision: {precision_logreg:.4f}\")\n",
    "print(f\"Recall: {recall_logreg:.4f}\")\n",
    "print(f\"F1-score: {f1_logreg:.4f}\")\n",
    "\n",
    "# Матрица ошибок\n",
    "print(\"\\nМатрица ошибок (Confusion Matrix):\")\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(cm)\n",
    "\n",
    "# Визуализация матрицы ошибок\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Предсказан 0', 'Предсказан 1'],\n",
    "            yticklabels=['Истинный 0', 'Истинный 1'])\n",
    "plt.title('Матрица ошибок логистической регрессии', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Истинный класс', fontsize=12)\n",
    "plt.xlabel('Предсказанный класс', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Отчёт по классификации\n",
    "print(\"\\nОтчёт по классификации:\")\n",
    "print(classification_report(y_test, y_pred_logreg, \n",
    "                            target_names=['No Default (0)', 'Default (1)']))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. ROC-кривая\n",
    "\n",
    "# %%\n",
    "# Вычисляем ROC-кривую\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba_logreg)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# ROC-кривая для бейзлайна (stratified)\n",
    "fpr_dummy, tpr_dummy, _ = roc_curve(y_test, y_proba_dummy)\n",
    "roc_auc_dummy = auc(fpr_dummy, tpr_dummy)\n",
    "\n",
    "# Строим ROC-кривую\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'Логистическая регрессия (AUC = {roc_auc:.3f})')\n",
    "plt.plot(fpr_dummy, tpr_dummy, color='navy', lw=2, linestyle='--',\n",
    "         label=f'Бейзлайн stratified (AUC = {roc_auc_dummy:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Случайный классификатор')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC-кривая: Логистическая регрессия vs Бейзлайн', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Добавляем аннотацию с лучшим порогом (точка с минимальным расстоянием до левого верхнего угла)\n",
    "distances = np.sqrt((1 - tpr)**2 + fpr**2)\n",
    "best_idx = np.argmin(distances)\n",
    "best_threshold = thresholds[best_idx]\n",
    "plt.plot(fpr[best_idx], tpr[best_idx], 'ro', markersize=10)\n",
    "plt.annotate(f'Лучший порог: {best_threshold:.3f}', \n",
    "             xy=(fpr[best_idx], tpr[best_idx]), \n",
    "             xytext=(fpr[best_idx] + 0.1, tpr[best_idx] - 0.1),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nЛучший порог отсечения (по минимальному расстоянию до (0,1)): {best_threshold:.3f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Влияние гиперпараметров на качество модели\n",
    "\n",
    "# %%\n",
    "# Извлекаем результаты GridSearchCV для анализа\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Выбираем только нужные колонки\n",
    "cv_results_display = cv_results[['param_logreg__C', 'mean_test_score', 'std_test_score']].copy()\n",
    "cv_results_display.columns = ['C (регуляризация)', 'Средний ROC-AUC', 'Стд. отклонение ROC-AUC']\n",
    "\n",
    "print(\"Результаты кросс-валидации для разных значений C:\")\n",
    "print(cv_results_display.sort_values('Средний ROC-AUC', ascending=False).to_string(index=False))\n",
    "\n",
    "# Визуализация влияния параметра C на ROC-AUC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(cv_results['param_logreg__C'], \n",
    "             cv_results['mean_test_score'], \n",
    "             yerr=cv_results['std_test_score'],\n",
    "             marker='o', markersize=8, capsize=5, capthick=2,\n",
    "             linestyle='-', linewidth=2)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Параметр регуляризации C (log scale)', fontsize=12)\n",
    "plt.ylabel('ROC-AUC (средний по CV)', fontsize=12)\n",
    "plt.title('Влияние параметра C на качество модели', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# Подсвечиваем лучшее значение C\n",
    "best_C = best_params['logreg__C']\n",
    "best_score = grid_search.best_score_\n",
    "plt.axvline(x=best_C, color='red', linestyle='--', alpha=0.7, label=f'Лучшее C = {best_C}')\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'parameter_C_influence.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Важность признаков\n",
    "\n",
    "# %%\n",
    "# Извлекаем коэффициенты логистической регрессии\n",
    "logreg_model = best_model.named_steps['logreg']\n",
    "feature_names = X.columns\n",
    "\n",
    "# Создаем DataFrame с коэффициентами\n",
    "coef_df = pd.DataFrame({\n",
    "    'Признак': feature_names,\n",
    "    'Коэффициент': logreg_model.coef_[0],\n",
    "    'Абсолютное значение': np.abs(logreg_model.coef_[0])\n",
    "}).sort_values('Абсолютное значение', ascending=False)\n",
    "\n",
    "print(\"10 наиболее важных признаков (по абсолютному значению коэффициента):\")\n",
    "print(coef_df.head(10).to_string(index=False))\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red' if x < 0 else 'green' for x in coef_df['Коэффициент'].head(15)]\n",
    "bars = plt.barh(coef_df['Признак'].head(15)[::-1], coef_df['Коэффициент'].head(15)[::-1], \n",
    "                color=colors[::-1])\n",
    "\n",
    "plt.xlabel('Коэффициент логистической регрессии', fontsize=12)\n",
    "plt.title('Важность признаков для предсказания дефолта', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Добавляем аннотации с значениями\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width if width > 0 else width - 0.01, \n",
    "             bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', \n",
    "             ha='left' if width > 0 else 'right', \n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Сравнение моделей\n",
    "\n",
    "# %%\n",
    "# Создаем таблицу сравнения моделей\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Модель': ['Бейзлайн (most_frequent)', 'Логистическая регрессия'],\n",
    "    'Accuracy': [accuracy_dummy, accuracy_logreg],\n",
    "    'ROC-AUC': [roc_auc_dummy, roc_auc_logreg],\n",
    "    'Precision': [np.nan, precision_logreg],\n",
    "    'Recall': [np.nan, recall_logreg],\n",
    "    'F1-score': [np.nan, f1_logreg]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"СРАВНЕНИЕ МОДЕЛЕЙ\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nТаблица сравнения метрик на тестовой выборке:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Сравнение Accuracy\n",
    "axes[0].bar(comparison_df['Модель'], comparison_df['Accuracy'], color=['skyblue', 'lightgreen'])\n",
    "axes[0].set_title('Сравнение Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for idx, value in enumerate(comparison_df['Accuracy']):\n",
    "    axes[0].text(idx, value + 0.01, f'{value:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Сравнение ROC-AUC\n",
    "axes[1].bar(comparison_df['Модель'], comparison_df['ROC-AUC'], color=['skyblue', 'lightgreen'])\n",
    "axes[1].set_title('Сравнение ROC-AUC', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('ROC-AUC', fontsize=12)\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for idx, value in enumerate(comparison_df['ROC-AUC']):\n",
    "    axes[1].text(idx, value + 0.01, f'{value:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. Текстовый отчёт и выводы\n",
    "\n",
    "# %%\n",
    "# Создаем директорию для артефактов\n",
    "artifacts_dir = Path(\"artifacts\")\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Сохраняем результаты\n",
    "comparison_df.to_csv(artifacts_dir / 'models_comparison.csv', index=False)\n",
    "cv_results_display.to_csv(artifacts_dir / 'grid_search_results.csv', index=False)\n",
    "coef_df.to_csv(artifacts_dir / 'feature_coefficients.csv', index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ТЕКСТОВЫЙ ОТЧЁТ И ВЫВОДЫ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. КРАТКОЕ ОПИСАНИЕ ЭКСПЕРИМЕНТА:\n",
    "   - Цель: Построить модель для прогнозирования дефолта по кредиту\n",
    "   - Данные: Синтетический датасет с 3000 наблюдениями и 15 признаками\n",
    "   - Целевая переменная: default (1 - дефолт, 0 - нет дефолта)\n",
    "   - Баланс классов: 60% (нет дефолта) / 40% (дефолт)\n",
    "\n",
    "2. РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА:\n",
    "\n",
    "   БЕЙЗЛАЙН-МОДЕЛЬ (DummyClassifier):\n",
    "   - Accuracy: {:.3f} (предсказывает наиболее частый класс)\n",
    "   - ROC-AUC: {:.3f} (случайный классификатор)\n",
    "\n",
    "   ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ:\n",
    "   - Лучший параметр C: {}\n",
    "   - Accuracy: {:.3f} (улучшение на {:.3f})\n",
    "   - ROC-AUC: {:.3f} (улучшение на {:.3f})\n",
    "   - Precision: {:.3f}\n",
    "   - Recall: {:.3f}\n",
    "   - F1-score: {:.3f}\n",
    "\n",
    "3. ВЫВОДЫ И ИНТЕРПРЕТАЦИЯ:\n",
    "\n",
    "   3.1. СРАВНЕНИЕ С БЕЙЗЛАЙНОМ:\n",
    "   - Логистическая регрессия значительно превосходит бейзлайн по всем метрикам\n",
    "   - Улучшение ROC-AUC на {:.3f} показывает, что модель действительно обучается\n",
    "     закономерностям в данных, а не просто угадывает\n",
    "\n",
    "   3.2. ВЛИЯНИЕ РЕГУЛЯРИЗАЦИИ:\n",
    "   - Параметр C = {} оказался оптимальным\n",
    "   - Слишком слабая регуляризация (большие C) может привести к переобучению\n",
    "   - Слишком сильная регуляризация (малые C) ухудшает качество предсказаний\n",
    "\n",
    "   3.3. ВАЖНОСТЬ ПРИЗНАКОВ:\n",
    "   - Наиболее важными признаками оказались: {}\n",
    "   - Признаки с положительными коэффициентами увеличивают вероятность дефолта\n",
    "   - Признаки с отрицательными коэффициентами уменьшают вероятность дефолта\n",
    "\n",
    "   3.4. ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ:\n",
    "   - Модель можно использовать для предварительной оценки риска дефолта\n",
    "   - ROC-AUC = {:.3f} указывает на хорошую разделяющую способность\n",
    "   - Для оптимизации бизнес-процессов можно настроить порог отсечения\n",
    "     (текущий лучший порог: {:.3f})\n",
    "\n",
    "   3.5. ОГРАНИЧЕНИЯ И ДАЛЬНЕЙШИЕ ШАГИ:\n",
    "   - Данные синтетические, в реальности качество может отличаться\n",
    "   - Можно попробовать более сложные модели (Random Forest, XGBoost)\n",
    "   - Полезно добавить feature engineering и обработку выбросов\n",
    "   - Для производственного использования нужна калибровка вероятностей\n",
    "\"\"\".format(\n",
    "    accuracy_dummy, roc_auc_dummy,\n",
    "    best_C, \n",
    "    accuracy_logreg, accuracy_logreg - accuracy_dummy,\n",
    "    roc_auc_logreg, roc_auc_logreg - roc_auc_dummy,\n",
    "    precision_logreg, recall_logreg, f1_logreg,\n",
    "    roc_auc_logreg - roc_auc_dummy,\n",
    "    best_C,\n",
    "    \", \".join(coef_df['Признак'].head(3).tolist()),\n",
    "    roc_auc_logreg,\n",
    "    best_threshold\n",
    "))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ФАЙЛЫ СОХРАНЕНЫ:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"- Графики: {figures_dir}/\")\n",
    "print(f\"- Артефакты: {artifacts_dir}/\")\n",
    "print(f\"- Основной ноутбук: HW05.ipynb\")\n",
    "print(\"\\nЭксперимент успешно завершён!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie-repositori-start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
